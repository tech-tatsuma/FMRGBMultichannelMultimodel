Namespace(data='violence_datasets', epochs=50, lr=0.001, test_size=0.2, patience=20, learnmethod='convlstm')
-----biginning training-----
Let's use 2 GPUs!
0it [00:00, ?it/s]0it [05:20, ?it/s]
shape of tensor before transform: torch.Size([64, 240, 426, 5])
shape of tensor before transform: torch.Size([64, 240, 134, 5])
shape of tensor before transform: torch.Size([64, 106, 80, 5])
shape of tensor before transform: torch.Size([64, 240, 134, 5])
shape of tensor before transform: torch.Size([64, 240, 426, 5])
shape of tensor before transform: torch.Size([64, 80, 106, 5])
shape of tensor before transform: torch.Size([64, 240, 426, 5])
shape of tensor before transform: torch.Size([64, 240, 426, 5])
shape of tensor before transform: torch.Size([64, 120, 142, 5])
shape of tensor before transform: torch.Size([64, 120, 120, 5])
shape of tensor before transform: torch.Size([64, 240, 426, 5])
shape of tensor before transform: torch.Size([64, 240, 134, 5])
shape of tensor before transform: torch.Size([64, 240, 136, 5])
shape of tensor before transform: torch.Size([64, 240, 136, 5])
shape of tensor before transform: torch.Size([64, 120, 150, 5])
shape of tensor before transform: torch.Size([64, 360, 640, 5])
shape of tensor before transform: torch.Size([64, 240, 426, 5])
shape of tensor before transform: torch.Size([64, 240, 426, 5])
shape of tensor before transform: torch.Size([64, 216, 194, 5])
shape of tensor before transform: torch.Size([64, 120, 68, 5])
Traceback (most recent call last):
  File "/home/furuya/FMRGB/FMRGBMultichannelMultimodel/train.py", line 259, in <module>
    train(opt)
  File "/home/furuya/FMRGB/FMRGBMultichannelMultimodel/train.py", line 169, in train
    outputs = model(inputs)
  File "/home/furuya/FMRGB/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/furuya/FMRGB/venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/furuya/FMRGB/venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 181, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/furuya/FMRGB/venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 89, in parallel_apply
    output.reraise()
  File "/home/furuya/FMRGB/venv/lib/python3.10/site-packages/torch/_utils.py", line 644, in reraise
    raise exception
torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/furuya/FMRGB/venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 64, in _worker
    output = module(*input, **kwargs)
  File "/home/furuya/FMRGB/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/furuya/FMRGB/FMRGBMultichannelMultimodel/model.py", line 202, in forward
    layer_output_list, last_state_list = super(ConvLSTM_FC, self).forward(input_tensor, hidden_state=hidden_state)
  File "/home/furuya/FMRGB/FMRGBMultichannelMultimodel/model.py", line 145, in forward
    h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],
  File "/home/furuya/FMRGB/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/furuya/FMRGB/FMRGBMultichannelMultimodel/model.py", line 75, in forward
    combined_conv = self.conv(combined) # 畳み込み演算を実行
  File "/home/furuya/FMRGB/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/furuya/FMRGB/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/furuya/FMRGB/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 47.54 GiB total capacity; 41.38 GiB already allocated; 277.88 MiB free; 45.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

